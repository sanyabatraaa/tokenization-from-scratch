{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUzrIGyQamBG",
        "outputId": "1f95a4c0-2921-4dd1-c1aa-39669db09201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_txt= f.read()\n",
        "\n",
        "print(\"Total number of character:\",len(raw_txt))\n",
        "print(raw_txt[:99])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Hello, world. This, is a test.\"\n",
        "result= re.split(r'(\\s)',text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiK7R5yBbLZf",
        "outputId": "754c63a9-fe35-46cd-aece-52835cb06b6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. This, is a test.\"\n",
        "result= re.split(r'([,.]|\\s)',text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r3vtzB3b_2V",
        "outputId": "8ffb4a2b-bcb4-42a7-b2e3-ff59b7094bc6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=[item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf5YZz07cRZo",
        "outputId": "67a44059-2eca-42ad-f754-d0e5237765b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. This, is-- a test?\"\n",
        "result= re.split(r'([,.?\":;_!\\'()]|--|\\s)',text)\n",
        "result=[item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVdNnrP-civG",
        "outputId": "0a158437-44fa-41e2-da96-b77d1a53d791"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed= re.split(r'([,.?\":;_!\\'()]|--|\\s)',raw_txt)\n",
        "preprocessed=[item for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eja4rFIzdva-",
        "outputId": "9daad6b7-7eea-4fbd-a6f4-3bf24def8480"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW70y-SadvT9",
        "outputId": "ca949170-71b2-476c-c421-fa8efc35b249"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words= sorted(set(preprocessed))\n",
        "vocab_size= len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEAscDQPdO2w",
        "outputId": "d442983b-504d-4955-deb7-d29b761ae2f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab={token:integer for integer,token in enumerate(all_words)}\n",
        "for i,item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i>=50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0f9Xb1GeWCa",
        "outputId": "f33b18c7-54af-4d0d-a358-2abf279d0944"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    preprocessed= re.split(r'([,.?\":;_!\\'()]|--|\\s)',text)\n",
        "    preprocessed=[item for item in preprocessed if item.strip()]\n",
        "    ids= [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text=\" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([.,?!()\\'])',r'\\1',text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "v5qg3bzzgDXg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= SimpleTokenizerV1(vocab)\n",
        "text= \"\"\"It's the last he painted, you know,\"\n",
        "Mrs, Gisburn said with pride.\"\"\"\n",
        "ids= tokenizer.encode(text)"
      ],
      "metadata": {
        "id": "VyvdI6QU9eS-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVR4zZkm-Zgh",
        "outputId": "25ccb895-630b-4f6e-f21c-c7b841b70c6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 5, 38, 851, 1108, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "giLWtWVF-bhC",
        "outputId": "fcb5ce09-7b5a-403c-801e-b53d6075120f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It\\' s the last he painted, you know, \" Mrs, Gisburn said with pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding** Special Context Tokens"
      ],
      "metadata": {
        "id": "5Ub2VOGX-6Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens= sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\",\"<|unk|>\"])\n",
        "vocab= {token:integer for integer,token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "GfKnVzBG-jt2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5YWMTmWAYrQ",
        "outputId": "dec6bb49-b6d3-40c6-a9d2-0837253c4e41"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1132"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxlQbT-VAbgv",
        "outputId": "4d94c476-3407-4483-96d7-536f37fee88d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        preprocessed = [\n",
        "            item if item in self.str_to_int\n",
        "            else \"<|unk|>\" for item in preprocessed\n",
        "        ]\n",
        "\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "EghIJLgIBCqd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= SimpleTokenizerV2(vocab)\n",
        "text1=\"Hello, do you like tea?\"\n",
        "text2=\"In the sunlit terraces of the palace.\"\n",
        "text=\" <|endoftext|> \".join((text1,text2))"
      ],
      "metadata": {
        "id": "pYvSVtkyFtkc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaLjcZKzGE1y",
        "outputId": "a2d67f51-d525-4987-e9ed-eb1e70bfa7b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYuZdCFyGRBW",
        "outputId": "3e3ee6d6-64bc-462e-9c98-aef7a50a56d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Oxe49OrXIX44",
        "outputId": "c937ba31-4421-4793-f941-7b7c7e1274e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BPE\n",
        "#HANDLES OOV AND HAS LESS VOCAB SIZE\n",
        "#SUBWORD TOKENIZATION"
      ],
      "metadata": {
        "id": "oUG3SnfVFYEZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M05yUv9dFYdZ",
        "outputId": "2369fd54-3786-466c-81c6-901ea244f84d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "     \"of someunknownPlace.\"\n",
        ")\n",
        "integer= tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "print(integer)\n",
        "string = tokenizer.decode(integer)\n",
        "print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgQs8Z47FYgR",
        "outputId": "5eb2a5d9-980e-4234-96dd-3ed84c4232f5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n",
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data sampling with sliding window"
      ],
      "metadata": {
        "id": "YPc-tVeSFYjZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_txt= f.read()\n",
        "\n",
        "encoded_txt= tokenizer.encode(raw_txt)\n",
        "print(len(encoded_txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZGp-2YdFYmM",
        "outputId": "2cd4c639-8838-438d-aa62-c12a678ec004"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_size=10\n",
        "x=encoded_txt[:context_size]\n",
        "y=encoded_txt[1:context_size+1]\n",
        "print(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEjM7IMuFYoa",
        "outputId": "c5c06947-eebe-4c8a-832f-73c68237046e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138] [367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,context_size+1):\n",
        "  context= encoded_txt[:i]\n",
        "  target= encoded_txt[i]\n",
        "  print(context,target)\n",
        "  print(tokenizer.decode(context),tokenizer.decode([target]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZwmOqtZFYr0",
        "outputId": "1fba700e-91d8-4e59-ed49-54c528cd1218"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[40] 367\n",
            "I  H\n",
            "[40, 367] 2885\n",
            "I H AD\n",
            "[40, 367, 2885] 1464\n",
            "I HAD  always\n",
            "[40, 367, 2885, 1464] 1807\n",
            "I HAD always  thought\n",
            "[40, 367, 2885, 1464, 1807] 3619\n",
            "I HAD always thought  Jack\n",
            "[40, 367, 2885, 1464, 1807, 3619] 402\n",
            "I HAD always thought Jack  G\n",
            "[40, 367, 2885, 1464, 1807, 3619, 402] 271\n",
            "I HAD always thought Jack G is\n",
            "[40, 367, 2885, 1464, 1807, 3619, 402, 271] 10899\n",
            "I HAD always thought Jack Gis burn\n",
            "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899] 2138\n",
            "I HAD always thought Jack Gisburn  rather\n",
            "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138] 257\n",
            "I HAD always thought Jack Gisburn rather  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implement data loader\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids=[]\n",
        "    self.target_ids=[]\n",
        "\n",
        "    token_ids= tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunk= token_ids[i:i+max_length]\n",
        "      target_chunk= token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.target_ids[idx]"
      ],
      "metadata": {
        "id": "AUmg8FImnfsb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt,batch_Size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
        "  tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset= GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
        "  dataloader= DataLoader(dataset,batch_size=batch_Size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "fmnbFRkZnf45"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_txt= f.read()"
      ],
      "metadata": {
        "id": "OEghvSOrnf9J"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "dataloader= create_dataloader_v1(raw_txt,batch_Size=4,max_length=20,stride=5,shuffle=True,drop_last=True,num_workers=0)\n",
        "data_iter= iter(dataloader)\n",
        "first_batch= next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "id": "3OIiK-IxngAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1ef941-b2fe-4927-e97d-32ce56e2a383"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  373,  7067, 29396, 18443, 12271,   290, 45592,    12, 14792,  5986,\n",
            "           351,   257,  8839,   326,  7284, 35924,   262, 12306,   395,  4133],\n",
            "        [   40, 27846,   706,   683,    11,  7425,   416,   465,   938,  1573,\n",
            "            13, 12622, 41379,   293,   373,    11,   287,  1109,    11,  5033],\n",
            "        [  887,   673,  3521,   470,  6842,   407,   284,   423,   477,   262,\n",
            "          8263,    12,  9649,   351,   607,    13,  1375,  3521,   470,  6842],\n",
            "        [  290,  1807,   683, 32081,   290, 44852,    88,    13,  2735,   314,\n",
            "          2497,   326,   339,   373, 21840,    13,   198,   198,     1,    40]]), tensor([[ 7067, 29396, 18443, 12271,   290, 45592,    12, 14792,  5986,   351,\n",
            "           257,  8839,   326,  7284, 35924,   262, 12306,   395,  4133,    13],\n",
            "        [27846,   706,   683,    11,  7425,   416,   465,   938,  1573,    13,\n",
            "         12622, 41379,   293,   373,    11,   287,  1109,    11,  5033,   262],\n",
            "        [  673,  3521,   470,  6842,   407,   284,   423,   477,   262,  8263,\n",
            "            12,  9649,   351,   607,    13,  1375,  3521,   470,  6842,   262],\n",
            "        [ 1807,   683, 32081,   290, 44852,    88,    13,  2735,   314,  2497,\n",
            "           326,   339,   373, 21840,    13,   198,   198,     1,    40,   373]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#token embeddings\n",
        "input_ids = torch.tensor([2, 3, 5, 1])\n",
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)\n",
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "id": "Yy5FTqJpngEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df09f0f-fb44-43f4-f074-2444ada8f9f1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.2141, -0.6169,  1.0109],\n",
            "        [ 0.1939, -0.6726, -0.7582],\n",
            "        [-0.9343, -0.4632, -0.0573],\n",
            "        [ 1.4513, -1.3632,  0.2089],\n",
            "        [ 1.5303,  1.0725, -0.2980],\n",
            "        [-0.7904, -0.9103, -0.1622]], requires_grad=True)\n",
            "tensor([[-0.9343, -0.4632, -0.0573],\n",
            "        [ 1.4513, -1.3632,  0.2089],\n",
            "        [-0.7904, -0.9103, -0.1622],\n",
            "        [ 0.1939, -0.6726, -0.7582]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#postional embeddings\n",
        "vocab_size=50257\n",
        "output_dim=256\n",
        "max_length=4\n",
        "dataloader= create_dataloader_v1(raw_txt,batch_Size=8,max_length=max_length,stride=max_length,shuffle=False)\n",
        "data_iter= iter(dataloader)\n",
        "inputs , targets= next(data_iter)"
      ],
      "metadata": {
        "id": "kKUjIvALngHS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embedding_layer= torch.nn.Embedding(vocab_size,output_dim)\n",
        "token_embeddings= token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "id": "6O1Sd27lngK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1331f72-3eca-4141-f54e-8848da434158"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length= max_length\n",
        "pos_embedding_layer= torch.nn.Embedding(context_length,output_dim)\n",
        "pos_embeddings= pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgX7znK_aWce",
        "outputId": "8767c384-687a-4478-cdc5-c14f0039726b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWIfmKBabG13",
        "outputId": "5b52bfe7-ccba-4498-b361-663682aa8354"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    }
  ]
}